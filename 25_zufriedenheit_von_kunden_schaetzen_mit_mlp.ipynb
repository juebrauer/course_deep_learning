{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Prof. Dr.-Ing. Jürgen Brauer, http://www.juergenbrauer.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the dataset\n",
    "\n",
    "The dataset used for this Jupyter notebook is called\n",
    "\n",
    "**\"Women's E-Commerce Clothing Reviews\"**\n",
    "\n",
    "and consists of 23,486 customer reviews and ratings.\n",
    "\n",
    "You can download it from Kaggle [here](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews).\n",
    "\n",
    "Each row corresponds to a customer review, and includes the following 10 columns:\n",
    "\n",
    "  * **Clothing ID:** Integer Categorical variable that refers to the specific piece being reviewed.\n",
    "  * **Age:** Positive Integer variable of the reviewers age.\n",
    "  * **Title:** String variable for the title of the review.\n",
    "  * **Review Text:** String variable for the review body.\n",
    "  * **Rating:** Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.\n",
    "  * **Recommended IND:** Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended.\n",
    "  * **Positive Feedback Count:** Positive Integer documenting the number of other customers who found this review positive.\n",
    "  * **Division Name:** Categorical name of the product high level division.\n",
    "  * **Department Name:** Categorical name of the product department name.\n",
    "  * **Class Name:** Categorical name of the product class name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filename = \"produktbewertungen.csv\"\n",
    "table = pd.read_csv( filename )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23481</th>\n",
       "      <td>23481</td>\n",
       "      <td>1104</td>\n",
       "      <td>34</td>\n",
       "      <td>Great dress for many occasions</td>\n",
       "      <td>I was very happy to snag this dress at such a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23482</th>\n",
       "      <td>23482</td>\n",
       "      <td>862</td>\n",
       "      <td>48</td>\n",
       "      <td>Wish it was made of cotton</td>\n",
       "      <td>It reminds me of maternity clothes. soft, stre...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23483</th>\n",
       "      <td>23483</td>\n",
       "      <td>1104</td>\n",
       "      <td>31</td>\n",
       "      <td>Cute, but see through</td>\n",
       "      <td>This fit well, but the top was very see throug...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23484</th>\n",
       "      <td>23484</td>\n",
       "      <td>1084</td>\n",
       "      <td>28</td>\n",
       "      <td>Very cute dress, perfect for summer parties an...</td>\n",
       "      <td>I bought this dress for a wedding i have this ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>23485</td>\n",
       "      <td>1104</td>\n",
       "      <td>52</td>\n",
       "      <td>Please make more like this one!</td>\n",
       "      <td>This dress in a lovely platinum is feminine an...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23486 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Clothing ID  Age  \\\n",
       "0               0          767   33   \n",
       "1               1         1080   34   \n",
       "2               2         1077   60   \n",
       "3               3         1049   50   \n",
       "4               4          847   47   \n",
       "...           ...          ...  ...   \n",
       "23481       23481         1104   34   \n",
       "23482       23482          862   48   \n",
       "23483       23483         1104   31   \n",
       "23484       23484         1084   28   \n",
       "23485       23485         1104   52   \n",
       "\n",
       "                                                   Title  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                Some major design flaws   \n",
       "3                                       My favorite buy!   \n",
       "4                                       Flattering shirt   \n",
       "...                                                  ...   \n",
       "23481                     Great dress for many occasions   \n",
       "23482                         Wish it was made of cotton   \n",
       "23483                              Cute, but see through   \n",
       "23484  Very cute dress, perfect for summer parties an...   \n",
       "23485                    Please make more like this one!   \n",
       "\n",
       "                                             Review Text  Rating  \\\n",
       "0      Absolutely wonderful - silky and sexy and comf...       4   \n",
       "1      Love this dress!  it's sooo pretty.  i happene...       5   \n",
       "2      I had such high hopes for this dress and reall...       3   \n",
       "3      I love, love, love this jumpsuit. it's fun, fl...       5   \n",
       "4      This shirt is very flattering to all due to th...       5   \n",
       "...                                                  ...     ...   \n",
       "23481  I was very happy to snag this dress at such a ...       5   \n",
       "23482  It reminds me of maternity clothes. soft, stre...       3   \n",
       "23483  This fit well, but the top was very see throug...       3   \n",
       "23484  I bought this dress for a wedding i have this ...       3   \n",
       "23485  This dress in a lovely platinum is feminine an...       5   \n",
       "\n",
       "       Recommended IND  Positive Feedback Count   Division Name  \\\n",
       "0                    1                        0       Initmates   \n",
       "1                    1                        4         General   \n",
       "2                    0                        0         General   \n",
       "3                    1                        0  General Petite   \n",
       "4                    1                        6         General   \n",
       "...                ...                      ...             ...   \n",
       "23481                1                        0  General Petite   \n",
       "23482                1                        0  General Petite   \n",
       "23483                0                        1  General Petite   \n",
       "23484                1                        2         General   \n",
       "23485                1                       22  General Petite   \n",
       "\n",
       "      Department Name Class Name  \n",
       "0            Intimate  Intimates  \n",
       "1             Dresses    Dresses  \n",
       "2             Dresses    Dresses  \n",
       "3             Bottoms      Pants  \n",
       "4                Tops    Blouses  \n",
       "...               ...        ...  \n",
       "23481         Dresses    Dresses  \n",
       "23482            Tops      Knits  \n",
       "23483         Dresses    Dresses  \n",
       "23484         Dresses    Dresses  \n",
       "23485         Dresses    Dresses  \n",
       "\n",
       "[23486 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want to do is to infer the Rating column from the text column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of reviews is <class 'list'>\n",
      "type of ratings is <class 'list'>\n",
      "type of a single review is <class 'str'>\n",
      "type of a single rating is <class 'int'>\n",
      "\n",
      "Example #1:\n",
      "Absolutely wonderful - silky and sexy and comfortable --> 4\n",
      "\n",
      "Example #2:\n",
      "I was surprised at the positive reviews for this product. its terrible! it cuts you in a weird place to make you look wide. the skirt is also not like the picture. its darker and heavier. the material isnt great. i had to return. --> 1\n"
     ]
    }
   ],
   "source": [
    "reviews = table[\"Review Text\"].tolist()\n",
    "ratings = table[\"Rating\"].tolist()\n",
    "\n",
    "print(\"type of reviews is\", type(reviews))\n",
    "print(\"type of ratings is\", type(ratings))\n",
    "\n",
    "print(\"type of a single review is\", type(reviews[0]))\n",
    "print(\"type of a single rating is\", type(ratings[0]))\n",
    "\n",
    "print(\"\\nExample #1:\")\n",
    "print(reviews[0], \"-->\", ratings[0])\n",
    "\n",
    "print(\"\\nExample #2:\")\n",
    "print(reviews[23478], \"-->\", ratings[23478])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we will have later some problems, if words as\n",
    "\n",
    "  - Nice\n",
    "  - nice\n",
    "  - nice,\n",
    "  - nice!  \n",
    "  \n",
    "will be treated as different words. For this we can use gensim's simple text preprocssing functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'this', 'is', 'some', 'test', 'line']\n",
      "['hello', 'this', 'is', 'some', 'test', 'line']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "print( gensim.utils.simple_preprocess (\"Hello, THIS is some test line!\") )\n",
    "print( gensim.utils.simple_preprocess (\"\\nHello, tHiS Is some\\t test line!\\n\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a word embedding using word2vec\n",
    "\n",
    "Now we will use the word2vec implementation from [gensim](https://radimrehurek.com/gensim/) in order to train a new word embedding that is suitable for our words/text.\n",
    "\n",
    "\n",
    "First, we have to make sure, that each review is a list of words and not a string, since this is expected from gensim's Word2Vec as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'a', 'long', 'long', 'long', 'string.']\n",
      "There are 23486 many reviews.\n",
      "['absolutely', 'wonderful', 'silky', 'and', 'sexy', 'and', 'comfortable']\n"
     ]
    }
   ],
   "source": [
    "some_str = \"I am a long long long string.\"\n",
    "print( some_str.split() )\n",
    "\n",
    "nr_reviews = len(reviews)\n",
    "print(\"There are\", nr_reviews, \"many reviews.\")\n",
    "\n",
    "reviews_as_lists_of_words = []\n",
    "for i in range(nr_reviews):\n",
    "    rev = reviews[i]\n",
    "    \n",
    "    # Some review texts are empty and\n",
    "    # Pandas uses then as data type \"float\"\n",
    "    if not isinstance(rev, str):\n",
    "        rev = \"\"\n",
    "    \n",
    "    # to lower case, remove escape sequences, remove commas and periods\n",
    "    # AND\n",
    "    # return not a string, but a list of words!\n",
    "    single_review_as_list_of_words = gensim.utils.simple_preprocess( rev )\n",
    "    \n",
    "    reviews_as_lists_of_words.append( single_review_as_list_of_words )\n",
    "\n",
    "print(reviews_as_lists_of_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDED_VECTOR_DIM = 150\n",
    "CONTEXT_WINDOW_SIZE = 10\n",
    "NR_TRAIN_EPOCHS = 10\n",
    "\n",
    "import gensim \n",
    "wordmodel = gensim.models.Word2Vec (reviews_as_lists_of_words,\n",
    "                                size=EMBEDDED_VECTOR_DIM,\n",
    "                                window=CONTEXT_WINDOW_SIZE,\n",
    "                                min_count=1,\n",
    "                                workers=10)\n",
    "wordmodel.train(reviews_as_lists_of_words,\n",
    "                total_examples=len(reviews_as_lists_of_words),\n",
    "                epochs=NR_TRAIN_EPOCHS)\n",
    "wordmodel.save(\"your_word_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some sanity checks with our word embedding\n",
    "\n",
    "Let's see whether the word vectors that we have learned make roughly sense.\n",
    "\n",
    "What are words considered as most similair to nice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 0.6222252249717712),\n",
       " ('great', 0.6218503713607788),\n",
       " ('wonderful', 0.5604586601257324),\n",
       " ('fabulous', 0.5403447151184082),\n",
       " ('lovely', 0.5238939523696899),\n",
       " ('fantastic', 0.5073368549346924),\n",
       " ('light', 0.4915662109851837),\n",
       " ('jacquard', 0.4514104127883911),\n",
       " ('pretty', 0.44627463817596436),\n",
       " ('avergage', 0.4431700110435486),\n",
       " ('excellent', 0.4312971234321594),\n",
       " ('smooth', 0.4312502145767212),\n",
       " ('substantial', 0.4300740659236908),\n",
       " ('beautiful', 0.4288889169692993),\n",
       " ('perfect', 0.42464226484298706)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = \"nice\"\n",
    "wordmodel.wv.most_similar (positive=w1, topn=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are words considered as similar to \"dress\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('romper', 0.5891741514205933),\n",
       " ('skirt', 0.5677682161331177),\n",
       " ('jumpsuit', 0.55530846118927),\n",
       " ('swimsuit', 0.5285894870758057),\n",
       " ('top', 0.5236107110977173),\n",
       " ('blouse', 0.4833352267742157),\n",
       " ('piece', 0.452787846326828),\n",
       " ('wedding', 0.44175517559051514),\n",
       " ('suit', 0.42936405539512634),\n",
       " ('jumper', 0.41757842898368835)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = \"dress\"\n",
    "wordmodel.wv.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are words considered as similar to \"elegant\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('classy', 0.8278968334197998),\n",
       " ('sophisticated', 0.716463029384613),\n",
       " ('chic', 0.7083356976509094),\n",
       " ('romantic', 0.666622519493103),\n",
       " ('effortless', 0.6549191474914551),\n",
       " ('bohemian', 0.6484301090240479),\n",
       " ('feminine', 0.6337804794311523),\n",
       " ('stylish', 0.6089857816696167),\n",
       " ('sexy', 0.6022568941116333),\n",
       " ('classic', 0.5979175567626953)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = \"elegant\"\n",
    "wordmodel.wv.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some vectors and play a little bit with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.55794805  3.2694407   0.16553666 -1.2091459  -0.7304475  -1.53515\n",
      " -1.4283302  -2.0727942  -0.73932743 -3.4050498   1.1890491   0.9677051\n",
      " -0.65841067  0.26415735 -0.07479114 -0.41697848 -0.5987646  -0.91773957\n",
      "  1.5866487   0.7581006   0.3038536  -1.6594889   2.8520114   1.7569945\n",
      "  0.21016447 -1.7710043  -0.52574295 -1.2346995  -0.8970529  -2.325719\n",
      "  2.6720257   3.3680732  -1.1971058   2.550115    1.2635094   0.69887936\n",
      " -0.4347923   2.8848739   2.2022245   0.5888121  -1.9034584  -2.2522545\n",
      " -1.3247584   0.22784592 -3.2799656   1.8455524   0.8136877   2.6375792\n",
      " -1.092729   -0.05050219 -0.02070649  1.4720976   2.370574    2.5714357\n",
      "  0.3303356   2.6223726  -0.47898963  4.0460186   0.05938768  0.6307582\n",
      "  1.6720892   2.2266588   0.8749312  -1.0896747   2.420996   -1.9835606\n",
      " -2.31568     0.35624397  0.00630749 -1.2240233   1.1348449   1.1633221\n",
      "  0.492213   -3.278445    2.4589984   0.1585826  -1.2814523  -3.2506769\n",
      " -1.4702188  -1.0559891  -0.37771904  1.1699936   1.0233893  -0.174841\n",
      " -0.14384009 -1.2360623   0.82211375 -0.08809823 -0.33325395  1.9906864\n",
      " -4.517865   -0.3305986   0.24472944  0.6520646  -0.5221622   1.1304362\n",
      " -2.3122294   0.00643376 -1.8482292  -0.7495677   1.1622856  -2.7331939\n",
      "  0.18231314  0.01373646  0.61479855  1.3286586  -0.9404099  -1.5456151\n",
      " -0.27544802 -0.91443586 -0.26926854  1.5681175  -0.25857434  0.9828211\n",
      "  0.36196902 -0.6385418  -1.507164    0.6456054   1.4414554   2.0177748\n",
      "  0.69418645 -0.10457808 -0.10319404 -0.7953141  -0.8541261  -0.7514196\n",
      "  0.32068464  1.3286017  -1.6324217  -0.1030753   1.2553343  -1.6435721\n",
      " -3.601309    0.03909479 -1.7299175   0.76434684  1.6333282   0.4892363\n",
      "  0.47185317  0.9384468  -1.5406748  -1.6759422   0.38648963  1.5257262\n",
      " -2.4881482   2.0236816  -1.0446825  -0.75802207 -0.598757   -1.1367148 ]\n",
      "Shape of vec_nice is (150,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21672/83220087.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  vec_nice = wordmodel[\"nice\"]\n"
     ]
    }
   ],
   "source": [
    "vec_nice = wordmodel[\"nice\"]\n",
    "print(vec_nice)\n",
    "print(\"Shape of vec_nice is\", vec_nice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the lengths of the reviews?\n",
    "\n",
    "The reviews have different lengths. That's clear. But, how different are there. Let us produce a histogram of the different lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length_per_review= [7, 51, 89, 19, 36, 89, 89, 92, 29, 60, 65, 8, 92, 65, 89, 89, 67, 52, 27, 51, 52, 92, 77, 36, 84, 60, 92, 45, 30, 78, 17, 59, 18, 75, 48, 16, 27, 62, 15, 23, 25, 42, 44, 86, 67, 39, 35, 10, 16, 45, 63, 28, 9, 86, 76, 35, 74, 27, 91, 48, 53, 85, 36, 22, 12, 43, 87, 89, 67, 50, 82, 90, 90, 46, 94, 88, 51, 36, 46, 76, 90, 10, 85, 91, 93, 93, 68, 91, 20, 70, 70, 75, 0, 0, 87, 82, 43, 31, 0, 83]\n"
     ]
    }
   ],
   "source": [
    "length_per_review = []\n",
    "for review_as_list_of_word in reviews_as_lists_of_words:\n",
    "    length_per_review.append( len(review_as_list_of_word) )\n",
    "print(\"length_per_review=\", length_per_review[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the histogram of the review lengths (in words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(length_per_review, bins=100)\n",
    "plt.suptitle(\"How often do certain review lengths occur?\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the training data\n",
    "\n",
    "For a given review (a sequence of words), we now want to have a sequence of word vectors. Then we have an appropriate input for our LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21672/697222449.py:28: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  word_vec = wordmodel[word]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "REVIEW_LENGTH = 100\n",
    "\n",
    "nr_samples =len(reviews_as_lists_of_words)\n",
    "nr_features = EMBEDDED_VECTOR_DIM\n",
    "nr_time_steps = REVIEW_LENGTH\n",
    "\n",
    "def to_sequence_data():\n",
    "    dataX, dataY = [], []\n",
    "    \n",
    "    for review_nr in range( nr_samples ):\n",
    "        \n",
    "        # get the next review as a list of words\n",
    "        review = reviews_as_lists_of_words[review_nr]\n",
    "        \n",
    "        # create a matrix M\n",
    "        # for each time step we have one line with a 100 (review-length) x 150-dim word-vector\n",
    "        M = np.zeros( nr_time_steps*nr_features )\n",
    "        \n",
    "        pos = 0\n",
    "        for word_nr in range( min(REVIEW_LENGTH,len(review)) ):\n",
    "            \n",
    "            # get the next word from the review\n",
    "            word = review[word_nr]\n",
    "            \n",
    "            # get the corresponding word vector from gensim\n",
    "            word_vec = wordmodel[word]\n",
    "            \n",
    "            # copy the word-vector to the matrix\n",
    "            M[pos:pos+nr_features] = word_vec\n",
    "            pos += nr_features\n",
    "        \n",
    "        # put matrix M to the list of input samples        \n",
    "        dataX.append( M )\n",
    "                \n",
    "        # put the rating of this review to list of desired outputs\n",
    "        dataY.append( ratings[review_nr] )\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "dataX, dataY = to_sequence_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have generated 23486 training samples.\n",
      "Shape of trainX is (23486, 15000)\n",
      "Shape of trainY is (23486,)\n",
      "\n",
      " [ 0.03837964 -1.45931387  1.6672287  ...  0.          0.\n",
      "  0.        ] --> 4\n"
     ]
    }
   ],
   "source": [
    "nr_training_samples = dataX.shape[0]\n",
    "print(\"I have generated\", nr_training_samples, \"training samples.\")\n",
    "\n",
    "print(\"Shape of trainX is\", dataX.shape)\n",
    "print(\"Shape of trainY is\", dataY.shape)\n",
    "\n",
    "print(\"\\n\",dataX[0], \"-->\", dataY[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retention of some test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18788 many review samples for training.\n",
      "There are 4698 many review samples for testing.\n"
     ]
    }
   ],
   "source": [
    "RATIO_TO_USE_FOR_TRAIN = 0.8\n",
    "\n",
    "nr_train_samples = int(dataX.shape[0]*RATIO_TO_USE_FOR_TRAIN)\n",
    "nr_test_samples = dataX.shape[0]-nr_train_samples\n",
    "\n",
    "trainX = dataX[0:nr_train_samples]\n",
    "testX = dataX[nr_train_samples:]\n",
    "\n",
    "trainY = dataY[0:nr_train_samples]\n",
    "testY = dataY[nr_train_samples:]\n",
    "\n",
    "print(\"There are\", trainX.shape[0],\"many review samples for training.\")\n",
    "print(\"There are\", testX.shape[0],\"many review samples for testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 100)               1500100   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,500,201\n",
      "Trainable params: 1,500,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "588/588 [==============================] - 27s 45ms/step - loss: 23.3030 - val_loss: 2.1815\n",
      "Epoch 2/20\n",
      "588/588 [==============================] - 27s 46ms/step - loss: 1.7437 - val_loss: 1.8500\n",
      "Epoch 3/20\n",
      "588/588 [==============================] - 27s 46ms/step - loss: 1.3522 - val_loss: 1.7036\n",
      "Epoch 4/20\n",
      "588/588 [==============================] - 28s 48ms/step - loss: 1.1923 - val_loss: 1.5516\n",
      "Epoch 5/20\n",
      "588/588 [==============================] - 27s 46ms/step - loss: 1.0298 - val_loss: 1.5492\n",
      "Epoch 6/20\n",
      "588/588 [==============================] - 28s 48ms/step - loss: 0.9091 - val_loss: 1.3677\n",
      "Epoch 7/20\n",
      "588/588 [==============================] - 29s 49ms/step - loss: 0.8140 - val_loss: 1.3323\n",
      "Epoch 8/20\n",
      "588/588 [==============================] - 28s 47ms/step - loss: 0.7380 - val_loss: 1.2544\n",
      "Epoch 9/20\n",
      "542/588 [==========================>...] - ETA: 1s - loss: 0.6825"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21672/2810444828.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m history = model.fit(trainX,\n\u001b[0m\u001b[1;32m      9\u001b[0m                     \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/env_generic/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m                 executor_type=executor_type)\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m       \u001b[0mcustom_gradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_graph_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(100, input_shape=(nr_time_steps*nr_features,)))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')    \n",
    "model.summary()\n",
    "history = model.fit(trainX,\n",
    "                    trainY,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    verbose=1,\n",
    "                    validation_data=(testX, testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4698, 15000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4698,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4698, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of testPredict is (4698,)\n"
     ]
    }
   ],
   "source": [
    "testPredict = testPredict.reshape(-1)\n",
    "print(\"Shape of testPredict is\", testPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.1738088, 3.9689116, 5.4475346, 3.798388 , 5.527534 , 5.651041 ,\n",
       "       2.6242702, 6.045885 , 5.2540245, 1.8267742], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPredict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 5, 5, 5, 5, 4, 2, 3, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In average we can estimate the rating on a 1-5 scale\n",
      "with an error of 0.888345502396247\n"
     ]
    }
   ],
   "source": [
    "avg_error = np.mean( np.abs(testY - testPredict) )\n",
    "print(\"In average we can estimate the rating on a 1-5 scale\\nwith an error of\", avg_error )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
