{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Inhaltsverzeichnis<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Einleitung\" data-toc-modified-id=\"Einleitung-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Einleitung</a></span></li><li><span><a href=\"#Verwendeter-Datensatz\" data-toc-modified-id=\"Verwendeter-Datensatz-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Verwendeter Datensatz</a></span></li><li><span><a href=\"#Daten-einlesen\" data-toc-modified-id=\"Daten-einlesen-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Daten einlesen</a></span></li><li><span><a href=\"#Spalten-selektieren,-Daten-plotten\" data-toc-modified-id=\"Spalten-selektieren,-Daten-plotten-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Spalten selektieren, Daten plotten</a></span></li><li><span><a href=\"#Daten-normalisieren\" data-toc-modified-id=\"Daten-normalisieren-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Daten normalisieren</a></span></li><li><span><a href=\"#Trainings--und-Testdaten-definieren\" data-toc-modified-id=\"Trainings--und-Testdaten-definieren-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Trainings- und Testdaten definieren</a></span></li><li><span><a href=\"#MLP-vorbereiten\" data-toc-modified-id=\"MLP-vorbereiten-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>MLP vorbereiten</a></span></li><li><span><a href=\"#MLP-trainieren\" data-toc-modified-id=\"MLP-trainieren-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>MLP trainieren</a></span></li><li><span><a href=\"#Modell-testen/anwenden\" data-toc-modified-id=\"Modell-testen/anwenden-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Modell testen/anwenden</a></span></li><li><span><a href=\"#Modell-speichern\" data-toc-modified-id=\"Modell-speichern-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Modell speichern</a></span></li><li><span><a href=\"#Modell-wiederherstellen-und-anwenden\" data-toc-modified-id=\"Modell-wiederherstellen-und-anwenden-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Modell wiederherstellen und anwenden</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einleitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Jupyter-Notebook durchlaufen wir alle relevanten Schritte des Machine-Learnings:\n",
    "1. Daten einlesen\n",
    "2. Daten vorverarbeiten\n",
    "3. Trainings- und Testdaten vorbereiten\n",
    "4. Machine-Learning Modell definieren (hier: ein MLP)\n",
    "5. Modell trainieren\n",
    "6. Modell testen/anwenden\n",
    "7. Modell speichern/wiederherstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verwendeter Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wollen mit realen Daten arbeiten. Bei [Kaggle](https://www.kaggle.com/) können wir viele Datensätze finden. Diesen hier verwenden wir im Folgenden:\n",
    "\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n",
    "\n",
    "Der Datensatz enthält in den Trainingsdaten 1460 Beispiele von Häusern, wobei deren Eigenschaften und deren jeweiliger tatsächlicher Verkaufspreis aufgeführt ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten einlesen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Datensätze liegen often als .csv Dateien vor. Diese können mittels der Bibliothek Pandas einfach eingelesen werden.\n",
    "\n",
    "Wenn Pandas noch installiert ist, kann diese Bibliothek mittels\n",
    "\n",
    "    pip install pandas\n",
    "\n",
    "unter der Anaconda Prompt installiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"daten/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "\n",
       "[3 rows x 81 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spalten selektieren, Daten plotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2003\n",
       "1       1976\n",
       "2       2001\n",
       "3       1915\n",
       "4       2000\n",
       "        ... \n",
       "1455    1999\n",
       "1456    1978\n",
       "1457    1941\n",
       "1458    1950\n",
       "1459    1965\n",
       "Name: YearBuilt, Length: 1460, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"YearBuilt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500\n",
       "1       181500\n",
       "2       223500\n",
       "3       140000\n",
       "4       250000\n",
       "         ...  \n",
       "1455    175000\n",
       "1456    210000\n",
       "1457    266500\n",
       "1458    142125\n",
       "1459    147500\n",
       "Name: SalePrice, Length: 1460, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"YearBuilt\"]\n",
    "y = df[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x,y, marker=\"+\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = df[[\"YearBuilt\", \"LotArea\"]].values\n",
    "#data_input = df[[\"YearBuilt\", \"LotArea\", \"OverallQual\"]].values\n",
    "\n",
    "nr_inputs = data_input.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2003,  8450],\n",
       "       [ 1976,  9600],\n",
       "       [ 2001, 11250],\n",
       "       ...,\n",
       "       [ 1941,  9042],\n",
       "       [ 1950,  9717],\n",
       "       [ 1965,  9937]], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output = df[\"SalePrice\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([208500, 181500, 223500, ..., 266500, 142125, 147500], dtype=int64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten normalisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_input = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_input_data = scaler_input.fit_transform(data_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94927536, 0.0334198 ],\n",
       "       [0.75362319, 0.03879502],\n",
       "       [0.93478261, 0.04650728],\n",
       "       ...,\n",
       "       [0.5       , 0.03618687],\n",
       "       [0.56521739, 0.03934189],\n",
       "       [0.67391304, 0.04037019]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scaled_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_output = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_output_data = scaler_output.fit_transform(data_output.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24107763],\n",
       "       [0.20358284],\n",
       "       [0.26190807],\n",
       "       ...,\n",
       "       [0.321622  ],\n",
       "       [0.14890293],\n",
       "       [0.15636717]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainings- und Testdaten definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaled_input_data[0:1000]\n",
    "y_train = scaled_output_data[0:1000]\n",
    "x_test  = scaled_input_data[1000:]\n",
    "y_test  = scaled_output_data[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 2)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94927536 0.0334198 ] --> [0.24107763]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0], \"-->\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(10,\n",
    "                             activation=\"relu\",\n",
    "                             input_shape=(nr_inputs,)))\n",
    "model.add(keras.layers.Dense(1,\n",
    "                             activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',               \n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 41\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/200\n",
      "1000/1000 [==============================] - 0s 243us/sample - loss: 0.0124 - accuracy: 0.0010\n",
      "Epoch 2/200\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0085 - accuracy: 0.0010\n",
      "Epoch 3/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0083 - accuracy: 0.0010\n",
      "Epoch 4/200\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0083 - accuracy: 0.0010\n",
      "Epoch 5/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0083 - accuracy: 0.0010\n",
      "Epoch 6/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0082 - accuracy: 0.0010\n",
      "Epoch 7/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0082 - accuracy: 0.0010\n",
      "Epoch 8/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0082 - accuracy: 0.0010\n",
      "Epoch 9/200\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0082 - accuracy: 0.0010\n",
      "Epoch 10/200\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0082 - accuracy: 0.0010\n",
      "Epoch 11/200\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0082 - accuracy: 0.0010\n",
      "Epoch 12/200\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0082 - accuracy: 0.0010\n",
      "Epoch 13/200\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0082 - accuracy: 0.0010\n",
      "Epoch 14/200\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0082 - accuracy: 0.0010\n",
      "Epoch 15/200\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 16/200\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 17/200\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 18/200\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 19/200\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 20/200\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 21/200\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 22/200\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 23/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 24/200\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 25/200\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 26/200\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 27/200\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 28/200\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 29/200\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 30/200\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 31/200\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 32/200\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 33/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 34/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0081 - accuracy: 0.0010\n",
      "Epoch 35/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 36/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 37/200\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 38/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 39/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 40/200\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 41/200\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 42/200\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 43/200\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 44/200\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 45/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 46/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 47/200\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 48/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 49/200\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 50/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 51/200\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 52/200\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 53/200\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 54/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 55/200\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 56/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 57/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 58/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 59/200\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 60/200\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 61/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 62/200\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 63/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 64/200\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 65/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 66/200\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 67/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 68/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 69/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 70/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 71/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 72/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 73/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 74/200\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 75/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 76/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 77/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 78/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 79/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 80/200\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 81/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 82/200\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 83/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 84/200\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 85/200\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 86/200\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 87/200\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 88/200\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 89/200\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 90/200\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 91/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 92/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 93/200\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 94/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 95/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 96/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 97/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 98/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 99/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 100/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 101/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 102/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 103/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 104/200\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 105/200\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 106/200\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 107/200\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 108/200\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 109/200\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 110/200\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 111/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 112/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 113/200\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 114/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 115/200\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 116/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 117/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 118/200\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 119/200\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 120/200\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 121/200\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 122/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 123/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 124/200\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 125/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 126/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 127/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 128/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 129/200\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 130/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 131/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 132/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 133/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 134/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 135/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 136/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 137/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 138/200\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 139/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 140/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 141/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 142/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 143/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 144/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 145/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 146/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 147/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 148/200\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 149/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 150/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 151/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 152/200\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 154/200\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 155/200\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 156/200\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 157/200\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 158/200\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 159/200\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 160/200\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 161/200\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 162/200\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 163/200\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 164/200\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 165/200\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 166/200\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 167/200\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 168/200\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 169/200\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 170/200\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 171/200\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 172/200\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 173/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 174/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 175/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 176/200\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 177/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 178/200\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 179/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 180/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 181/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 182/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 183/200\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 184/200\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 185/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 186/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 187/200\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 188/200\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 189/200\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 190/200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 191/200\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 192/200\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 193/200\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 194/200\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 195/200\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 196/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 197/200\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 198/200\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 199/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n",
      "Epoch 200/200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0080 - accuracy: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modell testen/anwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 1)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16285498],\n",
       "       [0.08715994],\n",
       "       [0.27294645],\n",
       "       [0.21321559],\n",
       "       [0.24665065]], dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dollar = scaler_output.inverse_transform( preds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 1)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_dollar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[152171.88 ],\n",
       "       [ 97663.875],\n",
       "       [231448.73 ],\n",
       "       [188436.55 ],\n",
       "       [212513.14 ],\n",
       "       [183616.14 ],\n",
       "       [181325.4  ],\n",
       "       [161469.45 ],\n",
       "       [228963.81 ],\n",
       "       [107282.48 ]], dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_dollar[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dollar = scaler_output.inverse_transform( y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 1)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_dollar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 82000.],\n",
       "       [ 86000.],\n",
       "       [232000.],\n",
       "       [136905.],\n",
       "       [181000.],\n",
       "       [149900.],\n",
       "       [163500.],\n",
       "       [ 88000.],\n",
       "       [240000.],\n",
       "       [102000.]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_dollar[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[152171.88] vs [82000.] --> Fehler: [-70171.875]\n",
      "[97663.875] vs [86000.] --> Fehler: [-11663.875]\n",
      "[231448.73] vs [232000.] --> Fehler: [551.265625]\n",
      "[188436.55] vs [136905.] --> Fehler: [-51531.546875]\n",
      "[212513.14] vs [181000.] --> Fehler: [-31513.140625]\n",
      "[183616.14] vs [149900.] --> Fehler: [-33716.140625]\n",
      "[181325.4] vs [163500.] --> Fehler: [-17825.40625]\n",
      "[161469.45] vs [88000.] --> Fehler: [-73469.453125]\n",
      "[228963.81] vs [240000.] --> Fehler: [11036.1875]\n",
      "[107282.48] vs [102000.] --> Fehler: [-5282.4765625]\n",
      "[168696.31] vs [135000.] --> Fehler: [-33696.3125]\n",
      "[169653.58] vs [100000.] --> Fehler: [-69653.578125]\n",
      "[112247.305] vs [165000.] --> Fehler: [52752.6953125]\n",
      "[87227.195] vs [85000.] --> Fehler: [-2227.1953125]\n",
      "[149471.73] vs [119200.] --> Fehler: [-30271.734375]\n",
      "[217325.39] vs [227000.] --> Fehler: [9674.609375]\n",
      "[217267.86] vs [203000.] --> Fehler: [-14267.859375]\n",
      "[188302.44] vs [187500.] --> Fehler: [-802.4375]\n",
      "[208055.55] vs [160000.] --> Fehler: [-48055.546875]\n",
      "[212175.48] vs [213490.] --> Fehler: [1314.515625]\n",
      "[220189.4] vs [176000.] --> Fehler: [-44189.40625]\n",
      "[222355.92] vs [194000.] --> Fehler: [-28355.921875]\n",
      "[119766.74] vs [87000.] --> Fehler: [-32766.7421875]\n",
      "[212513.14] vs [191000.] --> Fehler: [-21513.140625]\n",
      "[196424.5] vs [287000.] --> Fehler: [90575.5]\n",
      "[175231.02] vs [112500.] --> Fehler: [-62731.015625]\n",
      "[161588.12] vs [167500.] --> Fehler: [5911.875]\n",
      "[227982.97] vs [293077.] --> Fehler: [65094.03125]\n",
      "[135308.98] vs [105000.] --> Fehler: [-30308.984375]\n",
      "[163203.14] vs [118000.] --> Fehler: [-45203.140625]\n",
      "[95411.26] vs [160000.] --> Fehler: [64588.7421875]\n",
      "[118568.766] vs [197000.] --> Fehler: [78431.234375]\n",
      "[218368.58] vs [310000.] --> Fehler: [91631.421875]\n",
      "[218179.27] vs [230000.] --> Fehler: [11820.734375]\n",
      "[124731.5] vs [119750.] --> Fehler: [-4981.5]\n",
      "[161773.77] vs [84000.] --> Fehler: [-77773.765625]\n",
      "[234732.12] vs [315500.] --> Fehler: [80767.875]\n",
      "[219003.7] vs [287000.] --> Fehler: [67996.296875]\n",
      "[160102.83] vs [97000.] --> Fehler: [-63102.828125]\n",
      "[159990.94] vs [80000.] --> Fehler: [-79990.9375]\n",
      "[165020.5] vs [155000.] --> Fehler: [-10020.5]\n",
      "[169668.3] vs [173000.] --> Fehler: [3331.703125]\n",
      "[216906.7] vs [196000.] --> Fehler: [-20906.703125]\n",
      "[208760.11] vs [262280.] --> Fehler: [53519.890625]\n",
      "[191656.89] vs [278000.] --> Fehler: [86343.109375]\n",
      "[163322.77] vs [139600.] --> Fehler: [-23722.765625]\n",
      "[238235.17] vs [556581.] --> Fehler: [318345.828125]\n",
      "[209190.58] vs [145000.] --> Fehler: [-64190.578125]\n",
      "[186463.03] vs [115000.] --> Fehler: [-71463.03125]\n",
      "[145538.25] vs [84900.] --> Fehler: [-60638.25]\n",
      "[226930.] vs [176485.] --> Fehler: [-50445.]\n",
      "[231289.61] vs [200141.] --> Fehler: [-31148.609375]\n",
      "[167600.94] vs [165000.] --> Fehler: [-2600.9375]\n",
      "[155903.7] vs [144500.] --> Fehler: [-11403.703125]\n",
      "[224656.72] vs [255000.] --> Fehler: [30343.28125]\n",
      "[188158.83] vs [180000.] --> Fehler: [-8158.828125]\n",
      "[220245.36] vs [185850.] --> Fehler: [-34395.359375]\n",
      "[250576.78] vs [248000.] --> Fehler: [-2576.78125]\n",
      "[232958.64] vs [335000.] --> Fehler: [102041.359375]\n",
      "[126241.63] vs [220000.] --> Fehler: [93758.3671875]\n",
      "[210372.42] vs [213500.] --> Fehler: [3127.578125]\n",
      "[143888.] vs [81000.] --> Fehler: [-62888.]\n",
      "[85981.25] vs [90000.] --> Fehler: [4018.75]\n",
      "[105879.18] vs [110500.] --> Fehler: [4620.8203125]\n",
      "[173404.52] vs [154000.] --> Fehler: [-19404.515625]\n",
      "[221497.61] vs [328000.] --> Fehler: [106502.390625]\n",
      "[204974.11] vs [178000.] --> Fehler: [-26974.109375]\n",
      "[168120.44] vs [167900.] --> Fehler: [-220.4375]\n",
      "[169169.83] vs [151400.] --> Fehler: [-17769.828125]\n",
      "[146751.19] vs [135000.] --> Fehler: [-11751.1875]\n",
      "[157677.19] vs [135000.] --> Fehler: [-22677.1875]\n",
      "[177609.72] vs [154000.] --> Fehler: [-23609.71875]\n",
      "[141321.95] vs [91500.] --> Fehler: [-49821.953125]\n",
      "[182747.] vs [159500.] --> Fehler: [-23247.]\n",
      "[224653.58] vs [194000.] --> Fehler: [-30653.578125]\n",
      "[141164.34] vs [219500.] --> Fehler: [78335.65625]\n",
      "[130905.83] vs [170000.] --> Fehler: [39094.171875]\n",
      "[187344.61] vs [138800.] --> Fehler: [-48544.609375]\n",
      "[213613.33] vs [155900.] --> Fehler: [-57713.328125]\n",
      "[208251.53] vs [126000.] --> Fehler: [-82251.53125]\n",
      "[180500.97] vs [145000.] --> Fehler: [-35500.96875]\n",
      "[162201.69] vs [133000.] --> Fehler: [-29201.6875]\n",
      "[219426.] vs [192000.] --> Fehler: [-27426.]\n",
      "[166202.36] vs [160000.] --> Fehler: [-6202.359375]\n",
      "[218158.23] vs [187500.] --> Fehler: [-30658.234375]\n",
      "[206032.31] vs [147000.] --> Fehler: [-59032.3125]\n",
      "[165193.86] vs [83500.] --> Fehler: [-81693.859375]\n",
      "[227282.23] vs [252000.] --> Fehler: [24717.765625]\n",
      "[209791.16] vs [137500.] --> Fehler: [-72291.15625]\n",
      "[212780.89] vs [197000.] --> Fehler: [-15780.890625]\n",
      "[146044.62] vs [92900.] --> Fehler: [-53144.625]\n",
      "[202051.38] vs [160000.] --> Fehler: [-42051.375]\n",
      "[110674.336] vs [136500.] --> Fehler: [25825.6640625]\n",
      "[168464.78] vs [146000.] --> Fehler: [-22464.78125]\n",
      "[149117.83] vs [129000.] --> Fehler: [-20117.828125]\n",
      "[226174.08] vs [176432.] --> Fehler: [-49742.078125]\n",
      "[92205.05] vs [127000.] --> Fehler: [34794.953125]\n",
      "[186877.34] vs [170000.] --> Fehler: [-16877.34375]\n",
      "[121315.5] vs [128000.] --> Fehler: [6684.5]\n",
      "[192002.39] vs [157000.] --> Fehler: [-35002.390625]\n",
      "[103657.83] vs [60000.] --> Fehler: [-43657.828125]\n",
      "[177939.55] vs [119500.] --> Fehler: [-58439.546875]\n",
      "[156992.77] vs [135000.] --> Fehler: [-21992.765625]\n",
      "[159405.61] vs [159500.] --> Fehler: [94.390625]\n",
      "[161067.84] vs [106000.] --> Fehler: [-55067.84375]\n",
      "[215206.5] vs [325000.] --> Fehler: [109793.5]\n",
      "[205799.11] vs [179900.] --> Fehler: [-25899.109375]\n",
      "[254025.94] vs [274725.] --> Fehler: [20699.0625]\n",
      "[215248.78] vs [181000.] --> Fehler: [-34248.78125]\n",
      "[227453.34] vs [280000.] --> Fehler: [52546.65625]\n",
      "[208106.39] vs [188000.] --> Fehler: [-20106.390625]\n",
      "[186398.62] vs [205000.] --> Fehler: [18601.375]\n",
      "[152982.66] vs [129900.] --> Fehler: [-23082.65625]\n",
      "[151011.77] vs [134500.] --> Fehler: [-16511.765625]\n",
      "[145376.17] vs [117000.] --> Fehler: [-28376.171875]\n",
      "[233107.8] vs [318000.] --> Fehler: [84892.203125]\n",
      "[217430.03] vs [184100.] --> Fehler: [-33330.03125]\n",
      "[172338.31] vs [130000.] --> Fehler: [-42338.3125]\n",
      "[167822.36] vs [140000.] --> Fehler: [-27822.359375]\n",
      "[156708.34] vs [133700.] --> Fehler: [-23008.34375]\n",
      "[103384.09] vs [118400.] --> Fehler: [15015.90625]\n",
      "[226303.25] vs [212900.] --> Fehler: [-13403.25]\n",
      "[155227.67] vs [112000.] --> Fehler: [-43227.671875]\n",
      "[143554.97] vs [118000.] --> Fehler: [-25554.96875]\n",
      "[206144.19] vs [163900.] --> Fehler: [-42244.1875]\n",
      "[156837.33] vs [115000.] --> Fehler: [-41837.328125]\n",
      "[216322.73] vs [174000.] --> Fehler: [-42322.734375]\n",
      "[233866.86] vs [259000.] --> Fehler: [25133.140625]\n",
      "[228320.45] vs [215000.] --> Fehler: [-13320.453125]\n",
      "[185458.42] vs [140000.] --> Fehler: [-45458.421875]\n",
      "[113693.44] vs [135000.] --> Fehler: [21306.5625]\n",
      "[207911.69] vs [93500.] --> Fehler: [-114411.6875]\n",
      "[50522.645] vs [117500.] --> Fehler: [66977.35546875]\n",
      "[211758.69] vs [239500.] --> Fehler: [27741.3125]\n",
      "[212457.44] vs [169000.] --> Fehler: [-43457.4375]\n",
      "[107642.12] vs [102000.] --> Fehler: [-5642.1171875]\n",
      "[148154.5] vs [119000.] --> Fehler: [-29154.5]\n",
      "[36251.94] vs [94000.] --> Fehler: [57748.05859375]\n",
      "[186481.25] vs [196000.] --> Fehler: [9518.75]\n",
      "[104319.15] vs [144000.] --> Fehler: [39680.8515625]\n",
      "[145062.33] vs [139000.] --> Fehler: [-6062.328125]\n",
      "[186046.97] vs [197500.] --> Fehler: [11453.03125]\n",
      "[227468.75] vs [424870.] --> Fehler: [197401.25]\n",
      "[159585.42] vs [80000.] --> Fehler: [-79585.421875]\n",
      "[140679.56] vs [80000.] --> Fehler: [-60679.5625]\n",
      "[110568.61] vs [149000.] --> Fehler: [38431.390625]\n",
      "[200466.88] vs [180000.] --> Fehler: [-20466.875]\n",
      "[140319.92] vs [174500.] --> Fehler: [34180.078125]\n",
      "[106683.08] vs [116900.] --> Fehler: [10216.921875]\n",
      "[104856.61] vs [143000.] --> Fehler: [38143.390625]\n",
      "[145517.16] vs [124000.] --> Fehler: [-21517.15625]\n",
      "[177077.77] vs [149900.] --> Fehler: [-27177.765625]\n",
      "[165595.17] vs [230000.] --> Fehler: [64404.828125]\n",
      "[112675.914] vs [120500.] --> Fehler: [7824.0859375]\n",
      "[177395.78] vs [201800.] --> Fehler: [24404.21875]\n",
      "[186974.03] vs [218000.] --> Fehler: [31025.96875]\n",
      "[168704.55] vs [179900.] --> Fehler: [11195.453125]\n",
      "[218954.1] vs [230000.] --> Fehler: [11045.90625]\n",
      "[232802.11] vs [235128.] --> Fehler: [2325.890625]\n",
      "[180874.73] vs [185000.] --> Fehler: [4125.265625]\n",
      "[172821.75] vs [146000.] --> Fehler: [-26821.75]\n",
      "[164113.25] vs [224000.] --> Fehler: [59886.75]\n",
      "[171663.72] vs [129000.] --> Fehler: [-42663.71875]\n",
      "[181410.61] vs [108959.] --> Fehler: [-72451.609375]\n",
      "[200547.75] vs [194000.] --> Fehler: [-6547.75]\n",
      "[230831.53] vs [233170.] --> Fehler: [2338.46875]\n",
      "[231294.34] vs [245350.] --> Fehler: [14055.65625]\n",
      "[220821.14] vs [173000.] --> Fehler: [-47821.140625]\n",
      "[135352.61] vs [235000.] --> Fehler: [99647.390625]\n",
      "[263570.4] vs [625000.] --> Fehler: [361429.59375]\n",
      "[186603.12] vs [171000.] --> Fehler: [-15603.125]\n",
      "[158421.88] vs [163000.] --> Fehler: [4578.125]\n",
      "[215584.77] vs [171900.] --> Fehler: [-43684.765625]\n",
      "[159384.27] vs [200500.] --> Fehler: [41115.734375]\n",
      "[136800.98] vs [239000.] --> Fehler: [102199.015625]\n",
      "[209247.06] vs [285000.] --> Fehler: [75752.9375]\n",
      "[190574.16] vs [119500.] --> Fehler: [-71074.15625]\n",
      "[103186.62] vs [115000.] --> Fehler: [11813.3828125]\n",
      "[103624.56] vs [154900.] --> Fehler: [51275.4375]\n",
      "[151240.25] vs [93000.] --> Fehler: [-58240.25]\n",
      "[207423.47] vs [250000.] --> Fehler: [42576.53125]\n",
      "[221528.19] vs [392500.] --> Fehler: [170971.8125]\n",
      "[224740.31] vs [745000.] --> Fehler: [520259.6875]\n",
      "[108452.984] vs [120000.] --> Fehler: [11547.015625]\n",
      "[217411.92] vs [186700.] --> Fehler: [-30711.921875]\n",
      "[111944.33] vs [104900.] --> Fehler: [-7044.328125]\n",
      "[80017.266] vs [95000.] --> Fehler: [14982.734375]\n",
      "[215616.12] vs [262000.] --> Fehler: [46383.875]\n",
      "[219797.62] vs [195000.] --> Fehler: [-24797.625]\n",
      "[212720.61] vs [189000.] --> Fehler: [-23720.609375]\n",
      "[209270.72] vs [168000.] --> Fehler: [-41270.71875]\n",
      "[203020.4] vs [174000.] --> Fehler: [-29020.40625]\n",
      "[113071.91] vs [125000.] --> Fehler: [11928.09375]\n",
      "[206726.67] vs [165000.] --> Fehler: [-41726.671875]\n",
      "[174345.73] vs [158000.] --> Fehler: [-16345.734375]\n",
      "[222197.38] vs [176000.] --> Fehler: [-46197.375]\n",
      "[235638.5] vs [219210.] --> Fehler: [-16428.5]\n",
      "[98943.695] vs [144000.] --> Fehler: [45056.3046875]\n",
      "[218724.] vs [178000.] --> Fehler: [-40724.]\n",
      "[169664.16] vs [148000.] --> Fehler: [-21664.15625]\n",
      "[175727.05] vs [116050.] --> Fehler: [-59677.046875]\n",
      "[217111.47] vs [197900.] --> Fehler: [-19211.46875]\n",
      "[105879.18] vs [117000.] --> Fehler: [11120.8203125]\n",
      "[218619.39] vs [213000.] --> Fehler: [-5619.390625]\n",
      "[184316.] vs [153500.] --> Fehler: [-30816.]\n",
      "[214444.39] vs [271900.] --> Fehler: [57455.609375]\n",
      "[169208.75] vs [107000.] --> Fehler: [-62208.75]\n",
      "[221600.53] vs [200000.] --> Fehler: [-21600.53125]\n",
      "[161323.84] vs [140000.] --> Fehler: [-21323.84375]\n",
      "[227902.33] vs [290000.] --> Fehler: [62097.671875]\n",
      "[210325.98] vs [189000.] --> Fehler: [-21325.984375]\n",
      "[206542.92] vs [164000.] --> Fehler: [-42542.921875]\n",
      "[135005.28] vs [113000.] --> Fehler: [-22005.28125]\n",
      "[170494.73] vs [145000.] --> Fehler: [-25494.734375]\n",
      "[166202.9] vs [134500.] --> Fehler: [-31702.90625]\n",
      "[165600.4] vs [125000.] --> Fehler: [-40600.40625]\n",
      "[186108.34] vs [112000.] --> Fehler: [-74108.34375]\n",
      "[229031.34] vs [229456.] --> Fehler: [424.65625]\n",
      "[137231.36] vs [80500.] --> Fehler: [-56731.359375]\n",
      "[161799.86] vs [91500.] --> Fehler: [-70299.859375]\n",
      "[164204.38] vs [115000.] --> Fehler: [-49204.375]\n",
      "[170716.67] vs [134000.] --> Fehler: [-36716.671875]\n",
      "[148541.38] vs [143000.] --> Fehler: [-5541.375]\n",
      "[151715.61] vs [137900.] --> Fehler: [-13815.609375]\n",
      "[235489.22] vs [184000.] --> Fehler: [-51489.21875]\n",
      "[161143.14] vs [145000.] --> Fehler: [-16143.140625]\n",
      "[238128.73] vs [214000.] --> Fehler: [-24128.734375]\n",
      "[167749.5] vs [147000.] --> Fehler: [-20749.5]\n",
      "[227885.78] vs [367294.] --> Fehler: [139408.21875]\n",
      "[158810.94] vs [127000.] --> Fehler: [-31810.9375]\n",
      "[204604.95] vs [190000.] --> Fehler: [-14604.953125]\n",
      "[161253.9] vs [132500.] --> Fehler: [-28753.90625]\n",
      "[165477.66] vs [101800.] --> Fehler: [-63677.65625]\n",
      "[165899.05] vs [142000.] --> Fehler: [-23899.046875]\n",
      "[91277.83] vs [130000.] --> Fehler: [38722.171875]\n",
      "[104692.445] vs [138887.] --> Fehler: [34194.5546875]\n",
      "[208599.64] vs [175500.] --> Fehler: [-33099.640625]\n",
      "[229513.27] vs [195000.] --> Fehler: [-34513.265625]\n",
      "[232273.22] vs [142500.] --> Fehler: [-89773.21875]\n",
      "[225614.61] vs [265900.] --> Fehler: [40285.390625]\n",
      "[219648.52] vs [224900.] --> Fehler: [5251.484375]\n",
      "[228640.31] vs [248328.] --> Fehler: [19687.6875]\n",
      "[183881.69] vs [170000.] --> Fehler: [-13881.6875]\n",
      "[235312.83] vs [465000.] --> Fehler: [229687.171875]\n",
      "[122351.43] vs [230000.] --> Fehler: [107648.5703125]\n",
      "[200841.8] vs [178000.] --> Fehler: [-22841.796875]\n",
      "[222389.19] vs [186500.] --> Fehler: [-35889.1875]\n",
      "[190090.89] vs [169900.] --> Fehler: [-20190.890625]\n",
      "[101845.484] vs [129500.] --> Fehler: [27654.515625]\n",
      "[143359.33] vs [119000.] --> Fehler: [-24359.328125]\n",
      "[176530.81] vs [244000.] --> Fehler: [67469.1875]\n",
      "[209614.62] vs [171750.] --> Fehler: [-37864.625]\n",
      "[173929.44] vs [130000.] --> Fehler: [-43929.4375]\n",
      "[197701.75] vs [294000.] --> Fehler: [96298.25]\n",
      "[217196.97] vs [165400.] --> Fehler: [-51796.96875]\n",
      "[114778.51] vs [127500.] --> Fehler: [12721.4921875]\n",
      "[219296.39] vs [301500.] --> Fehler: [82203.609375]\n",
      "[97793.18] vs [99900.] --> Fehler: [2106.8203125]\n",
      "[225310.23] vs [190000.] --> Fehler: [-35310.234375]\n",
      "[175116.95] vs [151000.] --> Fehler: [-24116.953125]\n",
      "[247049.94] vs [181000.] --> Fehler: [-66049.9375]\n",
      "[156574.3] vs [128900.] --> Fehler: [-27674.296875]\n",
      "[161274.27] vs [161500.] --> Fehler: [225.734375]\n",
      "[112474.195] vs [180500.] --> Fehler: [68025.8046875]\n",
      "[204444.23] vs [181000.] --> Fehler: [-23444.234375]\n",
      "[205198.19] vs [183900.] --> Fehler: [-21298.1875]\n",
      "[93061.305] vs [122000.] --> Fehler: [28938.6953125]\n",
      "[236766.8] vs [378500.] --> Fehler: [141733.203125]\n",
      "[136095.86] vs [381000.] --> Fehler: [244904.140625]\n",
      "[162865.39] vs [144000.] --> Fehler: [-18865.390625]\n",
      "[216812.08] vs [260000.] --> Fehler: [43187.921875]\n",
      "[172526.84] vs [185750.] --> Fehler: [13223.15625]\n",
      "[177048.12] vs [137000.] --> Fehler: [-40048.125]\n",
      "[164604.36] vs [177000.] --> Fehler: [12395.640625]\n",
      "[83554.91] vs [139000.] --> Fehler: [55445.09375]\n",
      "[148834.36] vs [137000.] --> Fehler: [-11834.359375]\n",
      "[185692.44] vs [162000.] --> Fehler: [-23692.4375]\n",
      "[188535.95] vs [197900.] --> Fehler: [9364.046875]\n",
      "[220872.55] vs [237000.] --> Fehler: [16127.453125]\n",
      "[101859.64] vs [68400.] --> Fehler: [-33459.640625]\n",
      "[221541.86] vs [227000.] --> Fehler: [5458.140625]\n",
      "[201187.78] vs [180000.] --> Fehler: [-21187.78125]\n",
      "[184445.3] vs [150500.] --> Fehler: [-33945.296875]\n",
      "[177224.28] vs [139000.] --> Fehler: [-38224.28125]\n",
      "[104728.016] vs [169000.] --> Fehler: [64271.984375]\n",
      "[125525.414] vs [132500.] --> Fehler: [6974.5859375]\n",
      "[166777.05] vs [143000.] --> Fehler: [-23777.046875]\n",
      "[221546.48] vs [190000.] --> Fehler: [-31546.484375]\n",
      "[210455.62] vs [278000.] --> Fehler: [67544.375]\n",
      "[229666.53] vs [281000.] --> Fehler: [51333.46875]\n",
      "[176815.64] vs [180500.] --> Fehler: [3684.359375]\n",
      "[163203.14] vs [119500.] --> Fehler: [-43703.140625]\n",
      "[60768.95] vs [107500.] --> Fehler: [46731.05078125]\n",
      "[185719.31] vs [162900.] --> Fehler: [-22819.3125]\n",
      "[152317.88] vs [115000.] --> Fehler: [-37317.875]\n",
      "[171016.38] vs [138500.] --> Fehler: [-32516.375]\n",
      "[164599.25] vs [155000.] --> Fehler: [-9599.25]\n",
      "[213498.17] vs [140000.] --> Fehler: [-73498.171875]\n",
      "[338010.6] vs [160000.] --> Fehler: [-178010.59375]\n",
      "[156588.47] vs [154000.] --> Fehler: [-2588.46875]\n",
      "[219238.03] vs [225000.] --> Fehler: [5761.96875]\n",
      "[132732.31] vs [177500.] --> Fehler: [44767.6875]\n",
      "[210938.83] vs [290000.] --> Fehler: [79061.171875]\n",
      "[223514.05] vs [232000.] --> Fehler: [8485.953125]\n",
      "[211471.47] vs [130000.] --> Fehler: [-81471.46875]\n",
      "[233878.3] vs [325000.] --> Fehler: [91121.703125]\n",
      "[220051.55] vs [202500.] --> Fehler: [-17551.546875]\n",
      "[206846.95] vs [138000.] --> Fehler: [-68846.953125]\n",
      "[150143.03] vs [147000.] --> Fehler: [-3143.03125]\n",
      "[200800.86] vs [179200.] --> Fehler: [-21600.859375]\n",
      "[176568.28] vs [335000.] --> Fehler: [158431.71875]\n",
      "[223765.78] vs [203000.] --> Fehler: [-20765.78125]\n",
      "[204230.69] vs [302000.] --> Fehler: [97769.3125]\n",
      "[227253.94] vs [333168.] --> Fehler: [105914.0625]\n",
      "[150950.55] vs [119000.] --> Fehler: [-31950.546875]\n",
      "[177764.3] vs [206900.] --> Fehler: [29135.703125]\n",
      "[230796.83] vs [295493.] --> Fehler: [64696.171875]\n",
      "[216010.33] vs [208900.] --> Fehler: [-7110.328125]\n",
      "[230074.53] vs [275000.] --> Fehler: [44925.46875]\n",
      "[154996.45] vs [111000.] --> Fehler: [-43996.453125]\n",
      "[155580.03] vs [156500.] --> Fehler: [919.96875]\n",
      "[140811.19] vs [72500.] --> Fehler: [-68311.1875]\n",
      "[208264.05] vs [190000.] --> Fehler: [-18264.046875]\n",
      "[125590.06] vs [82500.] --> Fehler: [-43090.0625]\n",
      "[227510.7] vs [147000.] --> Fehler: [-80510.703125]\n",
      "[96946.04] vs [55000.] --> Fehler: [-41946.0390625]\n",
      "[110842.484] vs [79000.] --> Fehler: [-31842.484375]\n",
      "[187066.27] vs [130500.] --> Fehler: [-56566.265625]\n",
      "[107733.71] vs [256000.] --> Fehler: [148266.2890625]\n",
      "[214482.11] vs [176500.] --> Fehler: [-37982.109375]\n",
      "[227538.67] vs [227000.] --> Fehler: [-538.671875]\n",
      "[186998.02] vs [132500.] --> Fehler: [-54498.015625]\n",
      "[129870.305] vs [100000.] --> Fehler: [-29870.3046875]\n",
      "[126519.695] vs [125500.] --> Fehler: [-1019.6953125]\n",
      "[161771.14] vs [125000.] --> Fehler: [-36771.140625]\n",
      "[186143.58] vs [167900.] --> Fehler: [-18243.578125]\n",
      "[179723.17] vs [135000.] --> Fehler: [-44723.171875]\n",
      "[124571.82] vs [52500.] --> Fehler: [-72071.8203125]\n",
      "[228818.52] vs [200000.] --> Fehler: [-28818.515625]\n",
      "[178947.25] vs [128500.] --> Fehler: [-50447.25]\n",
      "[175014.5] vs [123000.] --> Fehler: [-52014.5]\n",
      "[230711.33] vs [155000.] --> Fehler: [-75711.328125]\n",
      "[220676.75] vs [228500.] --> Fehler: [7823.25]\n",
      "[113201.94] vs [177000.] --> Fehler: [63798.0625]\n",
      "[229742.47] vs [155835.] --> Fehler: [-73907.46875]\n",
      "[98862.66] vs [108500.] --> Fehler: [9637.34375]\n",
      "[195753.4] vs [262500.] --> Fehler: [66746.59375]\n",
      "[238139.97] vs [283463.] --> Fehler: [45323.03125]\n",
      "[228691.77] vs [215000.] --> Fehler: [-13691.765625]\n",
      "[28924.154] vs [122000.] --> Fehler: [93075.84570312]\n",
      "[178899.12] vs [200000.] --> Fehler: [21100.875]\n",
      "[164288.84] vs [171000.] --> Fehler: [6711.15625]\n",
      "[122718.805] vs [134900.] --> Fehler: [12181.1953125]\n",
      "[221532.81] vs [410000.] --> Fehler: [188467.1875]\n",
      "[219750.23] vs [235000.] --> Fehler: [15249.765625]\n",
      "[174596.77] vs [170000.] --> Fehler: [-4596.765625]\n",
      "[170361.6] vs [110000.] --> Fehler: [-60361.59375]\n",
      "[183491.95] vs [149900.] --> Fehler: [-33591.953125]\n",
      "[203368.77] vs [177500.] --> Fehler: [-25868.765625]\n",
      "[238192.48] vs [315000.] --> Fehler: [76807.515625]\n",
      "[107942.21] vs [189000.] --> Fehler: [81057.7890625]\n",
      "[238438.98] vs [260000.] --> Fehler: [21561.015625]\n",
      "[111875.516] vs [104900.] --> Fehler: [-6975.515625]\n",
      "[224539.72] vs [156932.] --> Fehler: [-67607.71875]\n",
      "[212509.16] vs [144152.] --> Fehler: [-68357.15625]\n",
      "[214123.92] vs [216000.] --> Fehler: [1876.078125]\n",
      "[216075.2] vs [193000.] --> Fehler: [-23075.203125]\n",
      "[172187.67] vs [127000.] --> Fehler: [-45187.671875]\n",
      "[212210.02] vs [144000.] --> Fehler: [-68210.015625]\n",
      "[224597.52] vs [232000.] --> Fehler: [7402.484375]\n",
      "[97663.875] vs [105000.] --> Fehler: [7336.125]\n",
      "[155171.] vs [165500.] --> Fehler: [10329.]\n",
      "[215812.78] vs [274300.] --> Fehler: [58487.21875]\n",
      "[223319.36] vs [466500.] --> Fehler: [243180.640625]\n",
      "[227384.16] vs [250000.] --> Fehler: [22615.84375]\n",
      "[230921.98] vs [239000.] --> Fehler: [8078.015625]\n",
      "[113479.09] vs [91000.] --> Fehler: [-22479.09375]\n",
      "[138317.94] vs [117000.] --> Fehler: [-21317.9375]\n",
      "[165151.9] vs [83000.] --> Fehler: [-82151.90625]\n",
      "[227009.23] vs [167500.] --> Fehler: [-59509.234375]\n",
      "[94862.375] vs [58500.] --> Fehler: [-36362.375]\n",
      "[182863.86] vs [237500.] --> Fehler: [54636.140625]\n",
      "[101260.24] vs [157000.] --> Fehler: [55739.7578125]\n",
      "[134695.03] vs [112000.] --> Fehler: [-22695.03125]\n",
      "[131639.25] vs [105000.] --> Fehler: [-26639.25]\n",
      "[100542.41] vs [125500.] --> Fehler: [24957.59375]\n",
      "[201616.67] vs [250000.] --> Fehler: [48383.328125]\n",
      "[98284.37] vs [136000.] --> Fehler: [37715.6328125]\n",
      "[237312.81] vs [377500.] --> Fehler: [140187.1875]\n",
      "[128332.016] vs [131000.] --> Fehler: [2667.984375]\n",
      "[217320.67] vs [235000.] --> Fehler: [17679.328125]\n",
      "[170699.95] vs [124000.] --> Fehler: [-46699.953125]\n",
      "[168490.2] vs [123000.] --> Fehler: [-45490.203125]\n",
      "[87403.414] vs [163000.] --> Fehler: [75596.5859375]\n",
      "[215640.69] vs [246578.] --> Fehler: [30937.3125]\n",
      "[231460.] vs [281213.] --> Fehler: [49753.]\n",
      "[240451.86] vs [160000.] --> Fehler: [-80451.859375]\n",
      "[99102.414] vs [137500.] --> Fehler: [38397.5859375]\n",
      "[143359.33] vs [138000.] --> Fehler: [-5359.328125]\n",
      "[106220.83] vs [137450.] --> Fehler: [31229.171875]\n",
      "[111492.39] vs [120000.] --> Fehler: [8507.609375]\n",
      "[219567.3] vs [193000.] --> Fehler: [-26567.296875]\n",
      "[221069.23] vs [193879.] --> Fehler: [-27190.234375]\n",
      "[239443.39] vs [282922.] --> Fehler: [43478.609375]\n",
      "[100657.24] vs [105000.] --> Fehler: [4342.7578125]\n",
      "[212428.53] vs [275000.] --> Fehler: [62571.46875]\n",
      "[176719.52] vs [133000.] --> Fehler: [-43719.515625]\n",
      "[195631.77] vs [112000.] --> Fehler: [-83631.765625]\n",
      "[88306.1] vs [125500.] --> Fehler: [37193.8984375]\n",
      "[220539.34] vs [215000.] --> Fehler: [-5539.34375]\n",
      "[225357.3] vs [230000.] --> Fehler: [4642.703125]\n",
      "[148154.5] vs [140000.] --> Fehler: [-8154.5]\n",
      "[141956.03] vs [90000.] --> Fehler: [-51956.03125]\n",
      "[228121.39] vs [257000.] --> Fehler: [28878.609375]\n",
      "[117164.336] vs [207000.] --> Fehler: [89835.6640625]\n",
      "[216224.81] vs [175900.] --> Fehler: [-40324.8125]\n",
      "[60416.266] vs [122500.] --> Fehler: [62083.734375]\n",
      "[229389.08] vs [340000.] --> Fehler: [110610.921875]\n",
      "[165606.25] vs [124000.] --> Fehler: [-41606.25]\n",
      "[188365.58] vs [223000.] --> Fehler: [34634.421875]\n",
      "[177609.72] vs [179900.] --> Fehler: [2290.28125]\n",
      "[174940.89] vs [127500.] --> Fehler: [-47440.890625]\n",
      "[212210.02] vs [136500.] --> Fehler: [-75710.015625]\n",
      "[190767.] vs [274970.] --> Fehler: [84203.]\n",
      "[159187.1] vs [144000.] --> Fehler: [-15187.09375]\n",
      "[163023.95] vs [142000.] --> Fehler: [-21023.953125]\n",
      "[212585.17] vs [271000.] --> Fehler: [58414.828125]\n",
      "[143795.3] vs [140000.] --> Fehler: [-3795.296875]\n",
      "[129326.29] vs [119000.] --> Fehler: [-10326.2890625]\n",
      "[197542.97] vs [182900.] --> Fehler: [-14642.96875]\n",
      "[249971.34] vs [192140.] --> Fehler: [-57831.34375]\n",
      "[175305.8] vs [143750.] --> Fehler: [-31555.796875]\n",
      "[118276.1] vs [64500.] --> Fehler: [-53776.1015625]\n",
      "[219640.36] vs [186500.] --> Fehler: [-33140.359375]\n",
      "[201627.95] vs [160000.] --> Fehler: [-41627.953125]\n",
      "[162596.55] vs [174000.] --> Fehler: [11403.453125]\n",
      "[176425.08] vs [120500.] --> Fehler: [-55925.078125]\n",
      "[235228.34] vs [394617.] --> Fehler: [159388.65625]\n",
      "[153596.03] vs [149700.] --> Fehler: [-3896.03125]\n",
      "[192814.28] vs [197000.] --> Fehler: [4185.71875]\n",
      "[112710.11] vs [191000.] --> Fehler: [78289.890625]\n",
      "[213595.34] vs [149300.] --> Fehler: [-64295.34375]\n",
      "[232349.27] vs [310000.] --> Fehler: [77650.734375]\n",
      "[98951.69] vs [121000.] --> Fehler: [22048.3125]\n",
      "[221735.11] vs [179600.] --> Fehler: [-42135.109375]\n",
      "[168209.75] vs [129000.] --> Fehler: [-39209.75]\n",
      "[198044.77] vs [157900.] --> Fehler: [-40144.765625]\n",
      "[212102.36] vs [240000.] --> Fehler: [27897.640625]\n",
      "[96351.984] vs [112000.] --> Fehler: [15648.015625]\n",
      "[160102.83] vs [92000.] --> Fehler: [-68102.828125]\n",
      "[180634.97] vs [136000.] --> Fehler: [-44634.96875]\n",
      "[228870.78] vs [287090.] --> Fehler: [58219.21875]\n",
      "[213498.17] vs [145000.] --> Fehler: [-68498.171875]\n",
      "[241958.12] vs [84500.] --> Fehler: [-157458.125]\n",
      "[219737.12] vs [185000.] --> Fehler: [-34737.125]\n",
      "[213553.77] vs [175000.] --> Fehler: [-38553.765625]\n",
      "[194589.77] vs [210000.] --> Fehler: [15410.234375]\n",
      "[134409.89] vs [266500.] --> Fehler: [132090.109375]\n",
      "[148388.25] vs [142125.] --> Fehler: [-6263.25]\n",
      "[169877.36] vs [147500.] --> Fehler: [-22377.359375]\n",
      "Durchschnittlicher Fehler in $: [43805.05245839]\n"
     ]
    }
   ],
   "source": [
    "nr_tests = len(y_test)\n",
    "sum_errors = 0.0\n",
    "for i in range(0,nr_tests):\n",
    "    error = gt_dollar[i] - preds_dollar[i]\n",
    "    print(\"{0} vs {1} --> Fehler: {2}\"\n",
    "          .format(preds_dollar[i],\n",
    "                  gt_dollar[i],\n",
    "                  error ))\n",
    "    sum_errors += abs(error)\n",
    "print(\"Durchschnittlicher Fehler in $:\", sum_errors/nr_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modell speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname1 = \"hauspreis_schaetzer.h5\"\n",
    "model.save(fname1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fname2 = \"scaler_output.pkl\"\n",
    "fobj = open(fname2, \"wb\")\n",
    "pickle.dump(scaler_output, fobj)\n",
    "fobj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modell wiederherstellen und anwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.models.load_model(fname1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 41\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fobj = open(fname2, \"rb\")\n",
    "scaler = pickle.load(fobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.preprocessing.data.MinMaxScaler"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = np.array( [[0.94927536, 0.0334198 ]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = new_model.predict( test_sample )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2573697]], dtype=float32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[220231.92]], dtype=float32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform( pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Inhaltsverzeichnis",
   "title_sidebar": "Inhalte",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
